---
title: "AI Task Forceで学んだ「不確実性との向き合い方」"
source: "https://engineering.mercari.com/blog/entry/20251210-ai-tf-facing-uncertainty/"
publishedDate: "2025-12-10"
category: "engineering"
feedName: "Mercari Engineering"
---

## はじめに

こんにちは。[@panorama](https://x.com/panorama32_ "@panorama") です。  
この記事は [Merpay & Mercoin Advent Calendar 2025](https://engineering.mercari.com/blog/entry/20251126-merpay-mercoin-advent-calendar-2025/ "Merpay & Mercoin Advent Calendar 2025") の 10 日目の記事です。

私は現在、7月に新設されたAI Task ForceというチームでEnablerを務めています。  
AI Task Forceは、メルカリをAI Nativeな組織へと変革するために立ち上がった100名規模のチームで、Enablerは「各領域でAI Nativeな業務変革を主導する役割」とされています。  
私の担当領域はFT Engineering(メルペイ・メルコインのエンジニアリング組織)です。

AI Task Forceについては以下の記事が詳しいです。

-   [メルカリが本気で始めた「AI-Native」化。100名規模のタスクフォースが立ち上がるまで](https://careers.mercari.com/mercan/articles/53708/)
-   [「AI Task Force」で変化を加速する。CTO @kimurasが描くメルカリの成長戦略](https://careers.mercari.com/mercan/articles/56200/)

また、[2025/12/02のAdvent Calendar](https://engineering.mercari.com/blog/entry/20251201-pj-double-towards-ai-native-development/)で@nnaakkaaiiさんから発表されたpj-doubleというプロジェクトでは、QA領域のTech Leadを担当しています。

![overview-of-asdd-20251210](https://storage.googleapis.com/prd-engineering-asset/2025/12/6e5dae32-asdd-1024x571-1.png)  
▲上記図の「Double QA」のTech Lead

AIを前提とした、仕様解析、テスト観点やテストケースの設計、自動テスト、そしてQA全体のワークフロー再設計に取り組みながら、「人間が何を行い、どのような業務体験を目指し、品質をどう担保するか」を日々議論しています。そして複数のパイロットチームとともに手法やツールの改善ループを回しています。

最初は「AI Task Forceとpj-doubleの話」(※1) や「なぜQA領域をやることになったか」、「どのような手法を試しているのか」を記事にしようと思っていました。しかしここ数ヶ月を振り返って、一番私に取って重大だったのは**マインドセットの変化**だと気付きました。  
そこで本記事では、AI Task Forceとpj-doubleで組織と業務のAI Native化を進める中で得られた、「不確実なものへの向き合い方」にフォーカスして書いていきます。

※1 簡潔に補足しておくとAI Task Forceとpj-doubleは現在は統合状態に近く、双方の文脈で自然に登場します。実は紆余曲折あってそのようになっているのですが、今回は本題ではないので割愛します。技術書典19にメルカリとして出版した「[Unleash Mercari Tech! vol.7](https://techbookfest.org/product/cXmRrrRCAVn3tTYfN7QPFJ?productVariantID=aFqdCda8MRkL5M0mbibGW5)」の第6章に「AI Task Forceに異動してから何をしてきたのか、pj-doubleがどのように拡大してAI Task Forceと統合状態になったか」などを書いていますので、もし気になる方はお手に取っていただけると。

## 不確実なものへの向き合い方

![不確実なものに向き合う](https://storage.googleapis.com/prd-engineering-asset/2025/12/d4f0ea05--1024x1024.png)

AI Task Forceで最初に直面したのは、答えのない領域でどう判断し、どう動くかという問いでした。

AI時代における組織や業務のあり方も、AI技術の未来も、誰も明確な答えを持っていません。  
そのため「失敗したらどうしよう」「確証がないままこれだけの人を巻き込んで進めて良いのか」と不安を抱く日々が続きました。

しかし私は次第に  
​

-   **不確実な中でも挑戦する意義**
-   **不確実な中で物事を決める、進める価値**

という2つの考え方に行き着き、迷いを生じずに動けるようになりました。

## 不確実な中でも挑戦する意義

私は当初、AI Task Forceの目指す壮大な目標と答えのない挑戦にどう向き合えば良いかわからずいました。  
一時は「社内固有の最適化だけ自分たちで行う。しかし一般的な大部分はソリューションプロバイダに任せてしまう方が、自分たちで挑戦するより合理的ではないか」という消極的な考え方になりました。

しかしその考え方はAI Task Forceの挑戦を根本的に否定するものでした。

たとえば、pj-doubleの取り組みではSDD (spec-driven development)に近い方法論が含まれており、こうした手法を検証することも活動の一部でした。  
一方で、KiroのようにSDDの実現を支援するための外部ソリューションも存在しており、そうしたツールの進化に期待すれば、自分たちで手法を磨いたり検証したりする挑戦は不要なのでは、と感じる瞬間もありました。

しかし最終的には

**「誰も正解がわからない。でも、手探りで失敗を繰り返したとしても進める価値がある」**

のがAI Native化だと考え直しました。

自分たちで解を見つけられるかもしれないし、他社の成功例を参考にすることになるかもしれない。結局ソリューションプロバイダのサービスを採用することになるかもしれない。  
AI Task Forceでは最初に自分たちが真にAI Nativeな組織に辿り着くことを目指していますが、たとえそうでなかったとしても、築き上げた下地や知見があればすぐに最適解に追従することができます。  
答えが出るまで待っていてはいつまで経っても変化が起きませんし、答えが出た頃にはまた新しい問いが生まれます。だから取り残されないために、挑戦し続けることが大切だと気付いたのです。

実はこの考え方は、メルカリが10年以上かけて育ててきたカルチャー、Valueの一つ”**Go Bold**”にも含まれていました。

Go Bold  
大胆にやろう

-   大きな成功のためには、思考のリミッターを外して、試行回数を増やすことが必要です。誰かと同じことをすれば普通の成果しか得られません。失敗や変化を恐れず、普通ではない大胆なチャレンジをし続けます。
-   失敗自体を責めることはしません。ナイストライを賞賛します。
-   ミッション達成のために一人一人がありたい姿を描き、周囲に示すことを重要視します。
-   成功・失敗に関わらず振り返りを言語化して共有することで、組織全体で素早く学び、次のチャレンジの糧にします。

私はこのバリューのことはとっくに理解したつもりになっていました。  
ですが今回の経験でバリューを再解釈し、メルカリはずっとこのスタンスだったのだと気付いたとき、とても背中を押されたような気持ちになりました。

## 不確実な中で物事を決める・進める価値

AI Task Forceは活動を開始して間もないチームです。  
そのため  
​

-   何を対象にAI Native化を進めるか
-   誰を巻き込み、どの規模でやるか
-   どの手法を採用するか

など、無数に決めることがあります。

私はAI Task Forceへ異動する前、メルカードを作るバックエンドチームに所属していました。  
そのチームではすでにある程度業務フローが確立しており、決定に関してはTech LeadやPM、 EM、 Directorと議論して決めていました。  
そのためAI Task Forceに来てしばらくはどんな選択肢に対しても「これを私が決めて良いのだろうか」「とりあえず自分の意見をまとめて”偉い人”(※2)に持っていこう」みたいな考え方をしていました。

※2 メルカリではTech LeadやEMも1つのRoleとしてフラットに考えるカルチャーがあるため、”偉い”という概念は本来ありません。この”偉い”という言葉は私が当時持っていた考え方を言語化しただけです。

しかしAI Task Forceで物事を決めようと思ったとき、**それを決める人は自分**でした。  
というより本当は以前からずっとそうだったのです。  
「権限がないから決められない」と思い込み、判断を他者に委ねていただけでした。  
そこで初めて**「決める」こと自体に大きな価値がある**ことに気付きました。  
特にそれが誰にもわからないこと、決められないこと、自分で決めたくないことであればあるほどです。

AI Task Forceが向き合う不確実性もまさにそうです。  
答えがないからこそ、決断して実行に移せることに大きな価値があります。  
もちろんその決断には自分なりの根拠があり、関係者から納得が得られる必要があります。  
ですがそういった細かいところは差し置いて、**「決める」「進める」ことが不確実な領域に向き合う上でとても大切**だとわかりました。  
(言葉の上でも”不確実”と言っているのだから、論理的に考えても当然ですよね。ですがそれをきちんと仕事上で実感したのはAI Task Forceに入ってからでした。)  
また可能であればその専門性をもって「決める」前に「主張する」ができるとなお良いことにも気付きました。  
決めることも重要ですが、決めるためには自分なりの意見が必要で、「主張する」「主張を持つ」という前段階があることも重要だと感じました。

たとえばpj-doubleのBackend QAでは、Scenarigo(※3)というテストツールを使うべきかという議論がありました。  
使わない理由としては、Scenarigoがyamlベースで独自文法を含むため、AIがその構造と意味を十分に理解できず、AIの効果を最大限発揮できない懸念があったことです。  
一方で使う理由としては、社内に既存の利用実績と知見があることと、仮に将来別ツールへ移行する場合でも、Backend QA全体フローから見れば置き換えの影響は限定的だと見積もれた点がありました。

これらを踏まえ、最終的には Scenarigo を採用することに決めました。  
どちらが最適かは現時点でも確定していません。  
しかし、自分なりの主張を持ち、決断し、言語化したことで、停滞していた状況が一気に動き始めたのを感じました。

これが「決める」「進める」ことが大切だと感じた場面の一例です。

※3 Go製のテストツール。[https://github.com/scenarigo/scenarigo](https://github.com/scenarigo/scenarigo)

## AI Nativeな未来での人間の価値

![人間が決める](https://storage.googleapis.com/prd-engineering-asset/2025/12/2f15fe0b--1024x683.png)

先ほどの「決める力」や「進める力」ですが、おそらくAIに関わらずTech LeadやEMといった方向性を示す必要がある役割を担う方に取っては、従来から求められてきた力だったと思います。  
しかし私は最近、これらは単なる役職上のスキルを超えて、**AI Nativeな未来において人間が持つ本質的な価値になる**のではないかと感じています。  
というのも、先ほどの私の例を思い出すと、「いくつもの選択肢を検討し、それぞれのパターンで起こることを予測し、意見を言う (ただし決めない)」というのはもはやAIができていることだからです。  
一方で責任と自信をもってして「決める」というのは以前の私と同じく、AIにもまだできていないことです。  
今年の春頃「AIは意思や欲望を持たない。だからそれを持つことが人間の価値だ。」という言葉をよく耳にしましたが、今ならその意味がよくわかります。

## 終わりに

私は上記のようなマインドセットの変遷を経て、不確実への不安(「失敗したらどうしよう。確証がないまま進めて良いのか」という気持ち)を払拭し、この挑戦をすること自体に大きな価値を見出せるようになりました。  
またAIというもの自体が不確実性をはらんでおり、時代も含めて不確実が大きいからこそ、決める行為そのものが価値になるということに気が付きました。  
決める力こそが人間に残る最後のクリエイティビティなのかもしれません。

この記事では、ここ数ヶ月で私の中で起こった考え方の変化を赤裸々に説明してみました。  
この気付きが、誰かの背中を押せていたら嬉しいと思います。

明日の記事はISSAさんです。引き続きお楽しみください。